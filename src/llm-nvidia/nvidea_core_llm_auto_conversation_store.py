# ============================================================
# NVIDIA Core LLM - Automatic Conversation Storage
# ------------------------------------------------------------
# ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” LangChainì„ í™œìš©í•˜ì—¬ ëŒ€í™” ë‚´ìš©ì„ ìë™ìœ¼ë¡œ
# Vector Store(FAISS)ì— ì €ì¥í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.
#
# ì£¼ìš” ê¸°ëŠ¥:
#  - ì‚¬ìš©ì ì…ë ¥ê³¼ LLM ì¶œë ¥ ìë™ ì €ì¥
#  - ì €ì¥ëœ ëŒ€í™”ë¥¼ Retrieverë¡œ ë¶ˆëŸ¬ì™€ ë§¥ë½ ìœ ì§€
#  - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ì„ ìœ„í•œ Prompt ì²´ì¸ êµ¬ì„±
# ============================================================
# ğŸ”‘ ê°„ë‹¨ ì„¤ëª… (ì°¨ì´ì )
# ì´ì „ ì²´ì¸: ë‹¨ìˆœíˆ Retriever â†’ Prompt â†’ LLM â†’ Parser íë¦„ìœ¼ë¡œ ë‹µë³€ë§Œ ìƒì„±. ëŒ€í™” ë‚´ìš©ì€ ë”°ë¡œ ì €ì¥ë˜ì§€ ì•ŠìŒ.
# ì§€ê¸ˆ ì²´ì¸: save_memory_and_get_output í•¨ìˆ˜ë¥¼ í†µí•´ ì‚¬ìš©ì ì…ë ¥ê³¼ LLM ì¶œë ¥ì„ convstoreì— ìë™ìœ¼ë¡œ ì¶”ê°€ ì €ì¥.
# ì¦‰, "User said ..." / "Agent said ..." í˜•íƒœë¡œ ë²¡í„°ìŠ¤í† ì–´ì— ê¸°ë¡ë¨.
# ì´í›„ ì§ˆì˜ ì‹œ, ì´ ì €ì¥ëœ ëŒ€í™” ë§¥ë½ì´ ê²€ìƒ‰ë˜ì–´ ë” ìì—°ìŠ¤ëŸ½ê³  ì¼ê´€ëœ ëŒ€í™”ê°€ ê°€ëŠ¥í•´ì§.
# ğŸ‘‰ ìš”ì•½í•˜ë©´: ì•„ê¹ŒëŠ” ë‹¨ìˆœ ì§ˆì˜ì‘ë‹µ ì²´ì¸, ì§€ê¸ˆì€ ëŒ€í™”ê°€ ìë™ìœ¼ë¡œ ë©”ëª¨ë¦¬ì— ì¶•ì ë˜ëŠ” ì²´ì¸ì…ë‹ˆë‹¤.
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from operator import itemgetter

########################################################################
## ëŒ€í™” ì €ì¥ì†Œ ì´ˆê¸°í™” ë° ë©”ì‹œì§€ ì¶”ê°€ ì •ì˜
convstore = FAISS.from_texts(conversation, embedding=embedder)

def save_memory_and_get_output(d, vstore):
    """'input'/'output' ë”•ì…”ë„ˆë¦¬ë¥¼ ë°›ì•„ convstoreì— ì €ì¥"""
    vstore.add_texts([f"ì‚¬ìš©ì: {d.get('input')}", f"ì—ì´ì „íŠ¸: {d.get('output')}"])
    return d.get('output')

########################################################################

# instruct_llm = ChatNVIDIA(model="mistralai/mixtral-8x22b-instruct-v0.1")

chat_prompt = ChatPromptTemplate.from_template(
    "ì§ˆë¬¸ì— ë‹µí•  ë•ŒëŠ” ë°˜ë“œì‹œ ì£¼ì–´ì§„ ë¬¸ë§¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."
    "\n\nê²€ìƒ‰ëœ ë¬¸ë§¥: {context}"
    "\n\nì‚¬ìš©ì ì§ˆë¬¸: {input}"
    "\nëŒ€í™”ì²´ë¡œ ë‹µë³€í•˜ì„¸ìš”. ëŒ€í™” íë¦„ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ í•˜ì„¸ìš”.\n"
    "[Agent]"
)

conv_chain = (
    {
        'context': convstore.as_retriever() | long_reorder | docs2str,
        'input': (lambda x:x)
    }
    | RunnableAssign({'output' : chat_prompt | instruct_llm | StrOutputParser()})
    | partial(save_memory_and_get_output, vstore=convstore)
)

# ëŒ€í™” ì‹¤í–‰ ì˜ˆì‹œ
pprint(conv_chain.invoke("ë‹¹ì‹ ì´ ë™ì˜í•´ì¤˜ì„œ ê¸°ë»ìš”! ê±°ê¸°ì„œ ì•„ì´ìŠ¤í¬ë¦¼ì„ ë¨¹ì„ ë‚ ì´ ê¸°ë‹¤ë ¤ì ¸ìš”! ì •ë§ ë§›ìˆëŠ” ìŒì‹ì´ì£ !"))
print()
pprint(conv_chain.invoke("ì œ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ìŒì‹ì´ ë¬´ì—‡ì¸ì§€ ë§ì¶œ ìˆ˜ ìˆë‚˜ìš”?"))
print()
pprint(conv_chain.invoke("ì‚¬ì‹¤ ì œê°€ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ê±´ ê¿€ì´ì—ìš”! ì™œ ê·¸ë ‡ê²Œ ìƒê°í–ˆëŠ”ì§€ ëª¨ë¥´ê² ë„¤ìš”."))
print()
pprint(conv_chain.invoke("ì•Œê² ì–´ìš”! ê´œì°®ì•„ìš”! ì´ì œ ì œ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ìŒì‹ì´ ë­”ì§€ ì•„ì‹œê² ì£ ?"))
